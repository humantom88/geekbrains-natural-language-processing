{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5822cce0dfea77bd1b5b649d2f91871660e133f67e755bca28128586ccbc8559"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Практическое задание к уроку \"Создание признакового пространства\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "source": [
    "### Загрузим данные"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_token</th>\n      <th>tweet_token_filtered</th>\n      <th>tweet_stemmed</th>\n      <th>tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when father is dysfunctional and is so selfish...</td>\n      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks for lyft credit cannot use cause they d...</td>\n      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday your majesty</td>\n      <td>[bihday, your, majesty]</td>\n      <td>[bihday, majesty]</td>\n      <td>[bihday, majesti]</td>\n      <td>[bihday, majesty]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model love you take with you all the time in ur</td>\n      <td>[model, love, you, take, with, you, all, the, ...</td>\n      <td>[model, love, take, time, ur]</td>\n      <td>[model, love, take, time, ur]</td>\n      <td>[model, love, take, time, ur]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsguide society now motivation</td>\n      <td>[factsguide, society, now, motivation]</td>\n      <td>[factsguide, society, motivation]</td>\n      <td>[factsguid, societi, motiv]</td>\n      <td>[factsguide, society, motivation]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "combine_df = pd.read_pickle(\"combine_df.pkl\")\n",
    "combine_df.head(5)"
   ]
  },
  {
   "source": [
    "### Задание 1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). \n",
    "- Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_stemmed_string'] = combine_df['tweet_stemmed'].apply(lambda tokens: ' '.join(tokens))\n",
    "combine_df['tweet_lemmatized_string'] = combine_df['tweet_lemmatized'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                               tweet_stemmed_string  \\\n",
       "0   1      father dysfunct selfish drag kid dysfunct run   \n",
       "1   2  thank lyft credit use caus offer wheelchair va...   \n",
       "2   3                                     bihday majesti   \n",
       "3   4                            model love take time ur   \n",
       "4   5                            factsguid societi motiv   \n",
       "\n",
       "                             tweet_lemmatized_string  label  \n",
       "0  father dysfunctional selfish drag kid dysfunct...    0.0  \n",
       "1  thank lyft credit use cause offer wheelchair v...    0.0  \n",
       "2                                     bihday majesty    0.0  \n",
       "3                            model love take time ur    0.0  \n",
       "4                      factsguide society motivation    0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet_stemmed_string</th>\n      <th>tweet_lemmatized_string</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>father dysfunct selfish drag kid dysfunct run</td>\n      <td>father dysfunctional selfish drag kid dysfunct...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>thank lyft credit use caus offer wheelchair va...</td>\n      <td>thank lyft credit use cause offer wheelchair v...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>bihday majesti</td>\n      <td>bihday majesty</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>model love take time ur</td>\n      <td>model love take time ur</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>factsguid societi motiv</td>\n      <td>factsguide society motivation</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = combine_df[['id', 'tweet_stemmed_string', 'tweet_lemmatized_string', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0    29720\n",
       "1.0     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17197"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "np.isnan(df['label']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-7-ea72096584b0>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['label'] = df['label'].apply(lambda y: 0 if np.isnan(y) else y)\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['label'].apply(lambda y: 0 if np.isnan(y) else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                               tweet_stemmed_string  \\\n",
       "0   1      father dysfunct selfish drag kid dysfunct run   \n",
       "1   2  thank lyft credit use caus offer wheelchair va...   \n",
       "2   3                                     bihday majesti   \n",
       "3   4                            model love take time ur   \n",
       "4   5                            factsguid societi motiv   \n",
       "\n",
       "                             tweet_lemmatized_string  label  \n",
       "0  father dysfunctional selfish drag kid dysfunct...    0.0  \n",
       "1  thank lyft credit use cause offer wheelchair v...    0.0  \n",
       "2                                     bihday majesty    0.0  \n",
       "3                            model love take time ur    0.0  \n",
       "4                      factsguide society motivation    0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet_stemmed_string</th>\n      <th>tweet_lemmatized_string</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>father dysfunct selfish drag kid dysfunct run</td>\n      <td>father dysfunctional selfish drag kid dysfunct...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>thank lyft credit use caus offer wheelchair va...</td>\n      <td>thank lyft credit use cause offer wheelchair v...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>bihday majesti</td>\n      <td>bihday majesty</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>model love take time ur</td>\n      <td>model love take time ur</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>factsguid societi motiv</td>\n      <td>factsguide society motivation</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "- Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "- Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "- Исключим стоп-слова с помощью stop_words='english'. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 1), \n",
    "                                   analyzer='word', \n",
    "                                   binary=False, \n",
    "                                   stop_words=\"english\", \n",
    "                                   max_df=0.9, \n",
    "                                   max_features=1000,)"
   ]
  },
  {
   "source": [
    "- Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names()."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "для stemmed count"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual  ad  adapt  ...  \\\n",
       "0    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "1    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "2    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "3    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "4    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "\n",
       "   yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0     0     0          0   0     0     0      0       0   0      0  \n",
       "1     0     0          0   0     0     0      0       0   0      0  \n",
       "2     0     0          0   0     0     0      0       0   0      0  \n",
       "3     0     0          0   0     0     0      0       0   0      0  \n",
       "4     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abl</th>\n      <th>absolut</th>\n      <th>accept</th>\n      <th>account</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actual</th>\n      <th>ad</th>\n      <th>adapt</th>\n      <th>...</th>\n      <th>yeah</th>\n      <th>year</th>\n      <th>yesterday</th>\n      <th>yo</th>\n      <th>yoga</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youtub</th>\n      <th>yr</th>\n      <th>yummi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "bag_of_words_stemmed = count_vectorizer.fit_transform(df['tweet_stemmed_string'])\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "stemmed_count_vectorizer_matrix = pd.DataFrame(bag_of_words_stemmed.toarray(), columns = feature_names)\n",
    "stemmed_count_vectorizer_matrix.head()"
   ]
  },
  {
   "source": [
    "для lemmatized count"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0     0           0       0        0    0       0      0         0      0   \n",
       "1     0           0       0        0    0       0      0         0      0   \n",
       "2     0           0       0        0    0       0      0         0      0   \n",
       "3     0           0       0        0    0       0      0         0      0   \n",
       "4     0           0       0        0    0       0      0         0      0   \n",
       "\n",
       "   add  ...  yesterday  yo  yoga  york  young  youth  youtube  yr  yrs  yummy  \n",
       "0    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "1    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "2    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "3    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "4    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>able</th>\n      <th>absolutely</th>\n      <th>accept</th>\n      <th>account</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actually</th>\n      <th>adapt</th>\n      <th>add</th>\n      <th>...</th>\n      <th>yesterday</th>\n      <th>yo</th>\n      <th>yoga</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youth</th>\n      <th>youtube</th>\n      <th>yr</th>\n      <th>yrs</th>\n      <th>yummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "bag_of_words_lemmatized = count_vectorizer.fit_transform(df['tweet_lemmatized_string'])\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "lemmatized_count_vectorizer_matrix = pd.DataFrame(bag_of_words_lemmatized.toarray(),\n",
    "                                                  columns = feature_names)\n",
    "lemmatized_count_vectorizer_matrix.head()"
   ]
  },
  {
   "source": [
    "### Задание 2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "- Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "- Исключим стоп-слова с помощью stop_words='english'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), \n",
    "                                   analyzer='word', \n",
    "                                   binary=False, \n",
    "                                   max_df=0.9, \n",
    "                                   max_features=1000,\n",
    "                                   stop_words='english')"
   ]
  },
  {
   "source": [
    "- Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names()."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "для stemmed tfidf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual   ad  adapt  ...  \\\n",
       "0  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "1  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "2  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "3  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "4  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "\n",
       "   yeah  year  yesterday   yo  yoga  york  young  youtub   yr  yummi  \n",
       "0   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "1   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "2   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "3   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "4   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abl</th>\n      <th>absolut</th>\n      <th>accept</th>\n      <th>account</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actual</th>\n      <th>ad</th>\n      <th>adapt</th>\n      <th>...</th>\n      <th>yeah</th>\n      <th>year</th>\n      <th>yesterday</th>\n      <th>yo</th>\n      <th>yoga</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youtub</th>\n      <th>yr</th>\n      <th>yummi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "bag_of_words_stemmed = tfidf_vectorizer.fit_transform(df['tweet_stemmed_string'])\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "stemmed_tfidf_vectorizer_matrix = pd.DataFrame(bag_of_words_stemmed.toarray(),\n",
    "                                  columns=feature_names)\n",
    "stemmed_tfidf_vectorizer_matrix.head()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "для lemmatized tfidf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "1   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "2   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "3   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "4   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "\n",
       "   add  ...  yesterday   yo  yoga  york  young  youth  youtube   yr  yrs  \\\n",
       "0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "1  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "2  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "3  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "4  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "\n",
       "   yummy  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>able</th>\n      <th>absolutely</th>\n      <th>accept</th>\n      <th>account</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actually</th>\n      <th>adapt</th>\n      <th>add</th>\n      <th>...</th>\n      <th>yesterday</th>\n      <th>yo</th>\n      <th>yoga</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youth</th>\n      <th>youtube</th>\n      <th>yr</th>\n      <th>yrs</th>\n      <th>yummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "bag_of_words_lemmatized = tfidf_vectorizer.fit_transform(df['tweet_lemmatized_string'])\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "lemmatized_tfidf_vectorizer_matrix = pd.DataFrame(bag_of_words_lemmatized.toarray(),\n",
    "                                  columns=feature_names)\n",
    "lemmatized_tfidf_vectorizer_matrix.head()"
   ]
  },
  {
   "source": [
    "### Задание 3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по изменяйте параметры что бы добиться лучшего скора) обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров, "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stem_count = stemmed_count_vectorizer_matrix.astype('float32')\n",
    "X_stem_tfidf = stemmed_tfidf_vectorizer_matrix.astype('float32')\n",
    "\n",
    "X_lem_count = lemmatized_count_vectorizer_matrix.astype('float32')\n",
    "X_lem_tfidf = lemmatized_tfidf_vectorizer_matrix.astype('float32')\n",
    "\n",
    "y = df['label'].astype('float32')\n",
    "\n",
    "results = []\n",
    "cases = [['stem count', X_stem_count], ['stem tfidf', X_stem_tfidf], ['lem count', X_lem_count], ['lem tfidf', X_lem_tfidf]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases:\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(case[1], y)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    results.append([\n",
    "        case[0], \n",
    "        mean_squared_error(y_test, y_pred), \n",
    "        mean_absolute_error(y_test, y_pred),\n",
    "        median_absolute_error(y_test, y_pred), \n",
    "        r2_score(y_test, y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['stem count', 0.037623715, 0.084559284, 0.034380622, 0.19739614672384798],\n",
       " ['stem tfidf', 0.034505844, 0.08229496, 0.029802574, 0.22882582361159987],\n",
       " ['lem count', 132.48676, 0.21605484, 0.036545515, -3125.2719999897663],\n",
       " ['lem tfidf', 41995.35, 1.9291726, 0.029538123, -1023236.0753148039]]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "source": [
    "### так же попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на качество сделайте выводы"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_numbers_of_features = [500, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_number_of_features in max_numbers_of_features:\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   analyzer='word', \n",
    "                                   binary=False, \n",
    "                                   max_df=0.9, \n",
    "                                   max_features=max_number_of_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "    X_lemmatized_tfidf = lemmatized_tfidf_vectorizer_matrix.astype('float32')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_lemmatized_tfidf, y)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    results.append([\n",
    "        f'{max_number_of_features} features lemmatized tfidf',\n",
    "        mean_squared_error(y_test, y_pred), \n",
    "        mean_absolute_error(y_test, y_pred),\n",
    "        median_absolute_error(y_test, y_pred), \n",
    "        r2_score(y_test, y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['stem count', 0.037623715, 0.084559284, 0.034380622, 0.19739614672384798],\n",
       " ['stem tfidf', 0.034505844, 0.08229496, 0.029802574, 0.22882582361159987],\n",
       " ['lem count', 132.48676, 0.21605484, 0.036545515, -3125.2719999897663],\n",
       " ['lem tfidf', 41995.35, 1.9291726, 0.029538123, -1023236.0753148039],\n",
       " ['500 features lemmatized tfidf',\n",
       "  0.03318647,\n",
       "  0.07966132,\n",
       "  0.029594153,\n",
       "  0.19139550979578346],\n",
       " ['3000 features lemmatized tfidf',\n",
       "  0.03437247,\n",
       "  0.08214512,\n",
       "  0.03028313,\n",
       "  0.21364391987409614]]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_n_components_numbers = [50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pca_n_components in pca_n_components_numbers:\n",
    "    pca = decomposition.PCA(n_components=pca_n_components)\n",
    "    pca.fit(X_lemmatized_tfidf)\n",
    "\n",
    "    X_lemmatized_tfidf_pca = pca.transform(X_lemmatized_tfidf)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_lemmatized_tfidf_pca, y)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    results.append([\n",
    "        f'PCA {pca_n_components} features lemmatized tfidf',\n",
    "        mean_squared_error(y_test, y_pred), \n",
    "        mean_absolute_error(y_test, y_pred),\n",
    "        median_absolute_error(y_test, y_pred), \n",
    "        r2_score(y_test, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results, columns=['case', 'mse', 'mae', 'median', 'r2 score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                case           mse       mae    median  \\\n",
       "0                         stem count      0.037624  0.084559  0.034381   \n",
       "1                         stem tfidf      0.034506  0.082295  0.029803   \n",
       "2                          lem count    132.486755  0.216055  0.036546   \n",
       "3                          lem tfidf  41995.351562  1.929173  0.029538   \n",
       "4      500 features lemmatized tfidf      0.033186  0.079661  0.029594   \n",
       "5     3000 features lemmatized tfidf      0.034372  0.082145  0.030283   \n",
       "6   PCA 50 features lemmatized tfidf      0.041267  0.089426  0.051518   \n",
       "7  PCA 100 features lemmatized tfidf      0.039927  0.088057  0.042172   \n",
       "\n",
       "       r2 score  \n",
       "0  1.973961e-01  \n",
       "1  2.288258e-01  \n",
       "2 -3.125272e+03  \n",
       "3 -1.023236e+06  \n",
       "4  1.913955e-01  \n",
       "5  2.136439e-01  \n",
       "6  7.159707e-02  \n",
       "7  1.105942e-01  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>case</th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>median</th>\n      <th>r2 score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>stem count</td>\n      <td>0.037624</td>\n      <td>0.084559</td>\n      <td>0.034381</td>\n      <td>1.973961e-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>stem tfidf</td>\n      <td>0.034506</td>\n      <td>0.082295</td>\n      <td>0.029803</td>\n      <td>2.288258e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lem count</td>\n      <td>132.486755</td>\n      <td>0.216055</td>\n      <td>0.036546</td>\n      <td>-3.125272e+03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lem tfidf</td>\n      <td>41995.351562</td>\n      <td>1.929173</td>\n      <td>0.029538</td>\n      <td>-1.023236e+06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>500 features lemmatized tfidf</td>\n      <td>0.033186</td>\n      <td>0.079661</td>\n      <td>0.029594</td>\n      <td>1.913955e-01</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3000 features lemmatized tfidf</td>\n      <td>0.034372</td>\n      <td>0.082145</td>\n      <td>0.030283</td>\n      <td>2.136439e-01</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>PCA 50 features lemmatized tfidf</td>\n      <td>0.041267</td>\n      <td>0.089426</td>\n      <td>0.051518</td>\n      <td>7.159707e-02</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PCA 100 features lemmatized tfidf</td>\n      <td>0.039927</td>\n      <td>0.088057</td>\n      <td>0.042172</td>\n      <td>1.105942e-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}