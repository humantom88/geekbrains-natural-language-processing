{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Практическое задание к уроку 8 \"Рекуррентные нейронные сети RNN LSTM GRU\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import os\n",
    "import re\n",
    "\n",
    "DATA_PATH = '../data'\n",
    "\n",
    "TRAIN_FILENAME = 'train.csv'\n",
    "TEST_FILENAME = 'train.csv'\n",
    "VALIDATION_FILENAME = 'train.csv'\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, TRAIN_FILENAME))\n",
    "df_test = pd.read_csv(os.path.join(DATA_PATH, TEST_FILENAME))\n",
    "df_val = pd.read_csv(os.path.join(DATA_PATH, VALIDATION_FILENAME))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Выполняем препроцессинг"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values\n",
    "text_corpus_test = df_test['text'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 1\n",
    "\n",
    "Построить сверточные архитектуры"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "def build_convolutional_model(word_count, training_length=1000):\n",
    "    model = Sequential()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=word_count, output_dim=30, input_length=training_length))\n",
    "    model.add(Conv1D(30, 3))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "conv_model = build_convolutional_model(word_count, training_length)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')\n",
    "conv_history = conv_model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_11_input'), name='embedding_11_input', description=\"created by layer 'embedding_11_input'\"), but it was called on an input with incompatible shape (None, 27).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_11_input'), name='embedding_11_input', description=\"created by layer 'embedding_11_input'\"), but it was called on an input with incompatible shape (None, 27).\n",
      "319/319 [==============================] - ETA: 0s - loss: 0.9163 - accuracy: 0.5533WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_11_input'), name='embedding_11_input', description=\"created by layer 'embedding_11_input'\"), but it was called on an input with incompatible shape (None, 27).\n",
      "319/319 [==============================] - 27s 82ms/step - loss: 0.9156 - accuracy: 0.5536 - val_loss: 0.5271 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "conv_score = conv_model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', conv_score[0])\n",
    "print('Test accuracy:', conv_score[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def build_rnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Embedding(\n",
    "            input_dim=word_count,\n",
    "            input_length=training_length,\n",
    "            output_dim=30,\n",
    "            trainable=True,\n",
    "            mask_zero=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(Masking(mask_value=0.0))\n",
    "\n",
    "    model.add(SimpleRNN(64))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "rnn_model = build_rnn_model()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')\n",
    "rnn_history = rnn_model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping]\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "319/319 [==============================] - 35s 110ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 2.1223 - val_accuracy: 0.7073\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "rnn_score = rnn_model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', rnn_score[0])\n",
    "print('Test accuracy:', rnn_score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "355/355 [==============================] - 3s 9ms/step - loss: 0.2156 - accuracy: 0.9695\n",
      "\n",
      "\n",
      "Test score: 0.21560560166835785\n",
      "Test accuracy: 0.9695426821708679\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def build_lstm_model():\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(\n",
    "      Embedding(input_dim=word_count,\n",
    "                input_length=training_length,\n",
    "                output_dim=30,\n",
    "                trainable=True,\n",
    "                mask_zero=True))\n",
    "  model.add(Masking(mask_value=0.0))\n",
    "  model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(\n",
    "      optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "lstm_model = build_lstm_model()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')\n",
    "lstm_history = lstm_model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=1,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping]\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "319/319 [==============================] - 37s 115ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 1.8006 - val_accuracy: 0.7086\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "lstm_score = lstm_model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', lstm_score[0])\n",
    "print('Test accuracy:', lstm_score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "355/355 [==============================] - 8s 15ms/step - loss: 0.6933 - accuracy: 0.4975\n",
      "\n",
      "\n",
      "Test score: 0.6933350563049316\n",
      "Test accuracy: 0.4973245859146118\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = pd.Dataframe([conv_score, rnn_score, lstm_score])\n",
    "results"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5822cce0dfea77bd1b5b649d2f91871660e133f67e755bca28128586ccbc8559"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}